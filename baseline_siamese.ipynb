{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"bioasq_data\": \"/home/aerossom/bioasq_data/\",\n",
      "    \"cooc_home\": \"/home/aerossom/bioasq_data/embeddings/cooccurrence_matrices\",\n",
      "    \"eval_home\": \"/home/aerossom/git_repos/Evaluation-Measures/\",\n",
      "    \"home_path\": \"/home/aerossom/git_repos/dmlpr\",\n",
      "    \"word2vec_model\": \"/home/aerossom/bioasq_data/embeddings/wikipedia-pubmed-and-PMC-w2v.bin\"\n",
      "}\n",
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "from os import path\n",
    "config_params = json.load(open('config.json','r'))['lisi1']\n",
    "print(json.dumps(config_params, indent=4, sort_keys=True))\n",
    "home_path = config_params[\"home_path\"]\n",
    "eval_home = config_params[\"eval_home\"]\n",
    "cooc_home = config_params[\"cooc_home\"]\n",
    "sys.path.append(path.abspath(\"../\"))\n",
    "sys.path.append(path.abspath(\"../bioasqdataset\"))\n",
    "import bioasqdataset.common.qa_data as qa_data\n",
    "import bioasqdataset.common.bioasq_util as bioasq_util\n",
    "word2vec_model = config_params[\"word2vec_model\"]\n",
    "sys.path.insert(0, eval_home)\n",
    "sys.path.insert(0, home_path+'/common')\n",
    "import map_callback\n",
    "import map_eval\n",
    "import bioasq_eval\n",
    "from elasticsearch import Elasticsearch\n",
    "import ranking\n",
    "import importlib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from operator import itemgetter \n",
    "import importlib\n",
    "import threading\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import pylab as plt\n",
    "import nlp_util\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, Conv3D, MaxPooling2D, GlobalMaxPool2D, GlobalMaxPool3D, MaxPool2D, MaxPool3D, Flatten, Dense, Dropout, Input, Concatenate, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "import p_tqdm\n",
    "from itertools import groupby\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import threading\n",
    "import random\n",
    "from scipy import spatial\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from random import shuffle\n",
    "import random\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "#tensorflow.keras.backend.set_image_data_format('channels_first')\n",
    "print(tf.keras.backend.image_data_format())\n",
    "import importlib\n",
    "importlib.reload(nlp_util)\n",
    "\n",
    "logging.config.fileConfig(home_path+\"/logging.conf\")\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "w2v_dim = 200\n",
    "max_terms = 40\n",
    "sim_dim = 1\n",
    "working_folder = 'working_folder'\n",
    "model_id = 'cnn_sim_dml'\n",
    "positive_rate = 0.5\n",
    "prep_step = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = KeyedVectors.load_word2vec_format(word2vec_model, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSalienceScore(qv, av, maxterms=40):\n",
    "    score = 0\n",
    "    imp_postag = set(['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'NN', 'NNS', 'NNP', 'NNPS', 'JJ'])\n",
    "    #imp_postag = set(['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP', 'WRB', 'NN', 'NNS', 'NNP', 'NNPS', 'MD'])\n",
    "    #imp_postag = set(['WRB','VB', 'VBD', 'VBG', 'VBN', 'VBP','VBZ', 'WDT', 'WP', 'WRB', 'NN', 'NNS', 'NNP', 'NNPS', 'MD'])\n",
    "    pq = nltk.pos_tag(qv)\n",
    "    pa = nltk.pos_tag(av)\n",
    "    out_m = np.zeros( (maxterms, maxterms) )\n",
    "    if len(pq)>maxterms:\n",
    "        pq = pq[0:maxterms]\n",
    "    if len(pa)>maxterms:\n",
    "        pa = pa[0:maxterms]\n",
    "    wq_m = np.zeros((maxterms,maxterms))\n",
    "    wa_m = np.zeros((maxterms,maxterms))\n",
    "\n",
    "    pq_l = [len(set([qt[1]]).intersection(imp_postag))+1 for qt in pq]\n",
    "    pa_l = [len(set([at[1]]).intersection(imp_postag))+1 for at in pa]\n",
    "\n",
    "    wq_m[0:len(pa_l) , 0:len(pq_l)]=pq_l\n",
    "    wa_m[0:len(pq_l) , 0:len(pa_l)]=pa_l\n",
    "\n",
    "    out_m = (wq_m.T + wa_m)/4\n",
    "    return out_m[0:maxterms,0:maxterms]\n",
    "\n",
    "def buildCosineSimMatrix(questions_answer_pairs, max_terms=40):\n",
    "    #build Question Answer Matrix Pairs\n",
    "    x = []\n",
    "    y = []    \n",
    "    data = p_tqdm.p_map(transform_single_pair,questions_answer_pairs)\n",
    "    x, y = zip(*data)\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "def transform_single_pair(pair, max_terms=40):\n",
    "    #Construct Question Answer Matrix Pairs\n",
    "    q_list = nlp_util.data_preprocess(pair['body'], prep_step)\n",
    "    #Answer processing\n",
    "    a_list = nlp_util.data_preprocess(pair['text'], prep_step)\n",
    "    #w2v representation matrices\n",
    "    q_w2v_matrix = np.zeros((max_terms,w2v_dim))\n",
    "    a_w2v_matrix = np.zeros((max_terms,w2v_dim))\n",
    "    #question transformation\n",
    "    q_term_i = 0\n",
    "    for i, q_i in enumerate(q_list):\n",
    "        if q_i in w2v:\n",
    "            q_w2v_matrix[q_term_i] = w2v[q_i]\n",
    "            q_term_i += 1\n",
    "            if q_term_i >= max_terms:\n",
    "                break\n",
    "    #passage transformation\n",
    "    a_term_i = 0\n",
    "    for i, a_i in enumerate(a_list):\n",
    "        if a_i in w2v:\n",
    "            a_w2v_matrix[a_term_i] = w2v[a_i]\n",
    "            a_term_i += 1\n",
    "            if a_term_i >= max_terms:\n",
    "                break\n",
    "    return (np.expand_dims(q_w2v_matrix, axis=-1), np.expand_dims(a_w2v_matrix, axis=-1), pair['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 128\n",
    "MARGIN = 0.4\n",
    "\n",
    "def pos_distance(y_true, y_pred):\n",
    "    positive_vec = y_pred[:, 0]\n",
    "    pos_dist = K.sum(positive_vec, axis=-1 )\n",
    "    return pos_dist\n",
    "\n",
    "def neg_distance(y_true, y_pred):\n",
    "    negative_vec = y_pred[:, 1]\n",
    "    neg_dist = K.sum(negative_vec, axis=-1 )\n",
    "    return neg_dist\n",
    "\n",
    "def triplet_loss_distance(y_true, y_pred, alpha = MARGIN):\n",
    "    positive_vec = y_pred[:, 0]\n",
    "    negative_vec = y_pred[:, 1]\n",
    "    \n",
    "    # distance between the anchor and the positive\n",
    "    pos_sum = K.sum( (positive_vec), axis=-1 )\n",
    "    neg_sum = K.sum( (negative_vec), axis=-1 )\n",
    "    \n",
    "    basic_loss = positive_vec - negative_vec + alpha\n",
    "    \n",
    "    loss = K.maximum(basic_loss,0.0) \n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sim_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 40, 200, 512)      5120      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 40, 200, 512)      0         \n",
      "_________________________________________________________________\n",
      "cnn_max_pool (GlobalMaxPooli (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1st (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "emdedding_128d (Dense)       (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 169,473\n",
      "Trainable params: 169,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 40, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 40, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sim_model (Sequential)          (None, 1)            169473      input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vectors (Concatenate)           (None, 2)            0           sim_model[1][0]                  \n",
      "                                                                 sim_model[2][0]                  \n",
      "==================================================================================================\n",
      "Total params: 169,473\n",
      "Trainable params: 169,473\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "sim_model = None\n",
    "train_model = None\n",
    "\n",
    "def make_sim_model(layer_name='sim_model'):\n",
    "    model = Sequential(name=layer_name)\n",
    "    model.add(Conv2D(512, (3, 3), padding='same',\n",
    "                 input_shape=(max_terms, w2v_dim, sim_dim)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(GlobalMaxPool2D(name='cnn_max_pool'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(256, name='dense_1st'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(128, name='emdedding_128d'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1, name='output'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "def make_siamese_model(sim_model):\n",
    "    positive = Input(shape=(max_terms, w2v_dim, sim_dim))\n",
    "    negative = Input(shape=(max_terms, w2v_dim, sim_dim))\n",
    "    positive_out = sim_model(positive)\n",
    "    negative_out = sim_model(negative)\n",
    "    vecs = Concatenate(axis=1, name='vectors')([positive_out, negative_out])\n",
    "    model = Model([positive, negative], vecs)\n",
    "    #model.compile('adam', triplet_loss_cosine, metrics=[cos_sim_pos, cos_sim_neg])\n",
    "    model.compile('adam', triplet_loss_distance, metrics=[pos_distance, neg_distance])\n",
    "    return model\n",
    "\n",
    "sim_model = make_sim_model()\n",
    "train_model = make_siamese_model(sim_model)\n",
    "sim_model.summary()\n",
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 ../bioasqdataset/generated_pairs\n",
      "Loaded BioasqUnalDataSet\n",
      "threshold  (0.0, 1)\n",
      "Number of pairs: 500248\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "\n",
    "#dataset_id = ('BiosqDataSet', config_params[\"train_data_dir\"])\n",
    "dataset_id = ('BioasqUnalDataSet', '../bioasqdataset/generated_pairs') \n",
    "ds = qa_data.DataSetFactory.loadDataSet(dataset_id[0],year='2016',\\\n",
    "                            path=dataset_id[1], threshold=(0.0,1))\n",
    "bioasq_dataset = ds.build_qa_pairs(ds)\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for p in bioasq_dataset:\n",
    "    pairs.append( { 'id': p.qi,  'body': p.q, 'text': p.a, 'label':p.l, 'params':p.params } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(set(map(itemgetter('id'), pairs)))\n",
    "random.shuffle(ids)\n",
    "qids_train, qids_val, qids_test = np.split( np.array(ids), [ int(.75 * len(ids)), int(.85 * len(ids)) ] )\n",
    "qids_train = set(qids_train)\n",
    "qids_val = set(qids_val)\n",
    "qids_test = set(qids_test)\n",
    "pairs_train = [ x for x in pairs if x['id'] in qids_train ]\n",
    "pairs_val = [ x for x in pairs if x['id'] in qids_val ]\n",
    "pairs_test = [ x for x in pairs if x['id'] in qids_test ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train # 373455, test # 75121, val #51672 \n"
     ]
    }
   ],
   "source": [
    "print('train # {}, test # {}, val #{} '.format(len(pairs_train),len(pairs_test),len(pairs_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(passages, batch_size = 32, threshold = None ):\n",
    "    \n",
    "    pos_passages = [ x for x in passages if x['label'] == 1 ] \n",
    "    neg_passages = [ x for x in passages if x['label'] == 0 ] \n",
    "    print('+({}) -({})'.format(len(pos_passages),len(neg_passages)))\n",
    "    \n",
    "    while True:\n",
    "        pos_sample = random.sample( pos_passages, int(batch_size/2) )\n",
    "        pos_sample = [ transform_single_pair(x) for x in pos_sample ]\n",
    "        neg_sample = random.sample( neg_passages, int(batch_size/2) )\n",
    "        neg_sample = [ transform_single_pair(x) for x in neg_sample ]\n",
    "        samples = pos_sample + neg_sample\n",
    "        random.shuffle(samples)\n",
    "        samples_q = [ x[0] for x in samples ]\n",
    "        samples_a = [ x[1] for x in samples ]\n",
    "        samples_l = [ [0,0] if x[2] == 1 else [0,1]  for x in samples ]\n",
    "        yield ( [np.array(samples_q), np.array(samples_a)], np.array(samples_l) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############\n",
    "# Call Backs\n",
    "# #############\n",
    "filepath = working_folder + \"/\" + model_id + \"_weights.best.h5\"\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', \n",
    "                                                verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "earlyStop = tf.keras.callbacks.EarlyStopping(restore_best_weights=True,\n",
    "                                              monitor='val_loss',\n",
    "                                              min_delta=0, \n",
    "                                              patience=5,\n",
    "                                              verbose=1, \n",
    "                                              mode='auto')\n",
    "\n",
    "best_model_path = 'working_folder/map_best_' + model_id + '.h5'\n",
    "\n",
    "\"\"\"\n",
    "Return the list of predictions in binary format {1: for related passages, 0: no related}\n",
    "\"\"\"\n",
    "def predict_function(x_samples):\n",
    "    x_samples = np.asarray([ x[0] for x in x_samples])\n",
    "    y_pred = sim_model.predict( x_samples )\n",
    "    y_pred = np.squeeze(y_pred)\n",
    "    y_pred = list(np.where(y_pred > 0.5, 1, 0))\n",
    "    return y_pred\n",
    "\n",
    "mapcallback = map_callback.MAPCallback(pairs_val, filepath=best_model_path, \n",
    "                                       predict_fc=predict_function, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+(24944) -(348511)\n",
      "+(3265) -(48407)\n",
      "Train for 500 steps, validate for 50 steps\n",
      "Epoch 1/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.2025 - pos_distance: 12.6073 - neg_distance: 22.8306\n",
      "Epoch 00001: val_loss improved from inf to 0.20526, saving model to working_folder/cnn_sim_dml_weights.best.h5\n",
      "500/500 [==============================] - 28s 57ms/step - loss: 0.2025 - pos_distance: 12.6029 - neg_distance: 22.8288 - val_loss: 0.2053 - val_pos_distance: 13.1797 - val_neg_distance: 23.7084\n",
      "Epoch 2/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1799 - pos_distance: 11.5844 - neg_distance: 23.2908\n",
      "Epoch 00002: val_loss improved from 0.20526 to 0.20439, saving model to working_folder/cnn_sim_dml_weights.best.h5\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.1798 - pos_distance: 11.5847 - neg_distance: 23.2952 - val_loss: 0.2044 - val_pos_distance: 11.9575 - val_neg_distance: 22.5297\n",
      "Epoch 3/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1759 - pos_distance: 10.9925 - neg_distance: 22.9437\n",
      "Epoch 00003: val_loss improved from 0.20439 to 0.18338, saving model to working_folder/cnn_sim_dml_weights.best.h5\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.1759 - pos_distance: 10.9939 - neg_distance: 22.9456 - val_loss: 0.1834 - val_pos_distance: 11.5857 - val_neg_distance: 22.8967\n",
      "Epoch 4/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1735 - pos_distance: 11.0680 - neg_distance: 23.0586\n",
      "Epoch 00004: val_loss did not improve from 0.18338\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.1734 - pos_distance: 11.0656 - neg_distance: 23.0624 - val_loss: 0.1896 - val_pos_distance: 13.5623 - val_neg_distance: 24.3401\n",
      "Epoch 5/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1616 - pos_distance: 10.1491 - neg_distance: 22.7109\n",
      "Epoch 00005: val_loss did not improve from 0.18338\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.1616 - pos_distance: 10.1546 - neg_distance: 22.7169 - val_loss: 0.1868 - val_pos_distance: 14.6969 - val_neg_distance: 25.6991\n",
      "Epoch 6/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1495 - pos_distance: 9.4504 - neg_distance: 22.7522\n",
      "Epoch 00006: val_loss improved from 0.18338 to 0.18020, saving model to working_folder/cnn_sim_dml_weights.best.h5\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.1495 - pos_distance: 9.4518 - neg_distance: 22.7561 - val_loss: 0.1802 - val_pos_distance: 12.2210 - val_neg_distance: 23.8112\n",
      "Epoch 7/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1416 - pos_distance: 9.0302 - neg_distance: 22.8570\n",
      "Epoch 00007: val_loss improved from 0.18020 to 0.16891, saving model to working_folder/cnn_sim_dml_weights.best.h5\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.1416 - pos_distance: 9.0267 - neg_distance: 22.8546 - val_loss: 0.1689 - val_pos_distance: 7.3633 - val_neg_distance: 19.2229\n",
      "Epoch 8/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1339 - pos_distance: 8.6550 - neg_distance: 23.0050\n",
      "Epoch 00008: val_loss did not improve from 0.16891\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.1339 - pos_distance: 8.6574 - neg_distance: 23.0106 - val_loss: 0.1769 - val_pos_distance: 13.0071 - val_neg_distance: 25.5841\n",
      "Epoch 9/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1297 - pos_distance: 8.2764 - neg_distance: 22.9492\n",
      "Epoch 00009: val_loss improved from 0.16891 to 0.15594, saving model to working_folder/cnn_sim_dml_weights.best.h5\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.1296 - pos_distance: 8.2768 - neg_distance: 22.9524 - val_loss: 0.1559 - val_pos_distance: 9.9632 - val_neg_distance: 23.1475\n",
      "Epoch 10/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1216 - pos_distance: 7.9830 - neg_distance: 23.2736\n",
      "Epoch 00010: val_loss improved from 0.15594 to 0.15428, saving model to working_folder/cnn_sim_dml_weights.best.h5\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.1215 - pos_distance: 7.9817 - neg_distance: 23.2740 - val_loss: 0.1543 - val_pos_distance: 11.1370 - val_neg_distance: 24.3575\n",
      "Epoch 11/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1174 - pos_distance: 7.8949 - neg_distance: 23.3911\n",
      "Epoch 00011: val_loss did not improve from 0.15428\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.1175 - pos_distance: 7.8952 - neg_distance: 23.3909 - val_loss: 0.1614 - val_pos_distance: 8.1800 - val_neg_distance: 21.5851\n",
      "Epoch 12/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1129 - pos_distance: 7.4508 - neg_distance: 23.5209\n",
      "Epoch 00012: val_loss improved from 0.15428 to 0.14790, saving model to working_folder/cnn_sim_dml_weights.best.h5\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.1128 - pos_distance: 7.4490 - neg_distance: 23.5266 - val_loss: 0.1479 - val_pos_distance: 9.8533 - val_neg_distance: 23.9179\n",
      "Epoch 13/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1113 - pos_distance: 7.4622 - neg_distance: 23.5514\n",
      "Epoch 00013: val_loss did not improve from 0.14790\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.1113 - pos_distance: 7.4620 - neg_distance: 23.5514 - val_loss: 0.1491 - val_pos_distance: 10.1200 - val_neg_distance: 24.1601\n",
      "Epoch 14/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1051 - pos_distance: 7.4306 - neg_distance: 23.8744\n",
      "Epoch 00014: val_loss improved from 0.14790 to 0.14042, saving model to working_folder/cnn_sim_dml_weights.best.h5\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.1050 - pos_distance: 7.4276 - neg_distance: 23.8753 - val_loss: 0.1404 - val_pos_distance: 8.6917 - val_neg_distance: 23.4866\n",
      "Epoch 15/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.1034 - pos_distance: 7.2911 - neg_distance: 23.8239\n",
      "Epoch 00015: val_loss did not improve from 0.14042\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.1034 - pos_distance: 7.2940 - neg_distance: 23.8279 - val_loss: 0.1450 - val_pos_distance: 11.4983 - val_neg_distance: 25.6962\n",
      "Epoch 16/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0995 - pos_distance: 7.2160 - neg_distance: 24.1590\n",
      "Epoch 00016: val_loss did not improve from 0.14042\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.0995 - pos_distance: 7.2111 - neg_distance: 24.1529 - val_loss: 0.1503 - val_pos_distance: 7.4256 - val_neg_distance: 21.3537\n",
      "Epoch 17/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0968 - pos_distance: 7.1516 - neg_distance: 24.3282\n",
      "Epoch 00017: val_loss did not improve from 0.14042\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.0968 - pos_distance: 7.1535 - neg_distance: 24.3264 - val_loss: 0.1581 - val_pos_distance: 11.2430 - val_neg_distance: 25.7296\n",
      "Epoch 18/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0943 - pos_distance: 6.9759 - neg_distance: 24.2647\n",
      "Epoch 00018: val_loss did not improve from 0.14042\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.0942 - pos_distance: 6.9797 - neg_distance: 24.2697 - val_loss: 0.1408 - val_pos_distance: 8.7562 - val_neg_distance: 23.5245\n",
      "Epoch 19/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0922 - pos_distance: 7.0560 - neg_distance: 24.4637\n",
      "Epoch 00019: val_loss improved from 0.14042 to 0.13693, saving model to working_folder/cnn_sim_dml_weights.best.h5\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.0924 - pos_distance: 7.0483 - neg_distance: 24.4488 - val_loss: 0.1369 - val_pos_distance: 9.7703 - val_neg_distance: 23.9968\n",
      "Epoch 20/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0916 - pos_distance: 7.0051 - neg_distance: 24.7046\n",
      "Epoch 00020: val_loss did not improve from 0.13693\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.0916 - pos_distance: 7.0009 - neg_distance: 24.7033 - val_loss: 0.1395 - val_pos_distance: 9.0699 - val_neg_distance: 23.0269\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499/500 [============================>.] - ETA: 0s - loss: 0.0905 - pos_distance: 6.9489 - neg_distance: 24.5235\n",
      "Epoch 00021: val_loss did not improve from 0.13693\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.0905 - pos_distance: 6.9500 - neg_distance: 24.5271 - val_loss: 0.1542 - val_pos_distance: 13.4465 - val_neg_distance: 28.1067\n",
      "Epoch 22/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0846 - pos_distance: 6.8807 - neg_distance: 24.8711\n",
      "Epoch 00022: val_loss did not improve from 0.13693\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.0845 - pos_distance: 6.8767 - neg_distance: 24.8717 - val_loss: 0.1403 - val_pos_distance: 9.5177 - val_neg_distance: 24.7942\n",
      "Epoch 23/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0831 - pos_distance: 6.8127 - neg_distance: 25.1449\n",
      "Epoch 00023: val_loss did not improve from 0.13693\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.0832 - pos_distance: 6.8131 - neg_distance: 25.1440 - val_loss: 0.1399 - val_pos_distance: 9.9265 - val_neg_distance: 23.9275\n",
      "Epoch 24/30\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0827 - pos_distance: 6.9788 - neg_distance: 25.1093\n",
      "Epoch 00024: val_loss did not improve from 0.13693\n",
      "Restoring model weights from the end of the best epoch.\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 0.0827 - pos_distance: 6.9849 - neg_distance: 25.1174 - val_loss: 0.1550 - val_pos_distance: 14.5989 - val_neg_distance: 28.7911\n",
      "Epoch 00024: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 30\n",
    "history = train_model.fit_generator(\n",
    "    data_generator(pairs_train, batch_size=batch_size, threshold = (0.4, 1)), \n",
    "    validation_data=data_generator(pairs_val, batch_size=batch_size, threshold = (0.0, 1)),\n",
    "    steps_per_epoch=500,#int(len(pairs_train)/batch_size), \n",
    "    validation_steps=50,#int(len(pairs_val)/batch_size),\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint, earlyStop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.load_weights(filepath)\n",
    "weights_sim_model = train_model.get_layer('sim_model').get_weights()\n",
    "sim_model = make_sim_model() #assumed it returns the model of simmodel\n",
    "sim_model.set_weights(weights_sim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([ y['label'] for y in pairs_test ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = [i for i, x in enumerate(pairs_test) if x['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28172, 28173, 28174, 28175, 28176, 28177, 28178, 28179, 28180, 28181]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[0.0015252]]\n",
      "[[0.98740315]]\n"
     ]
    }
   ],
   "source": [
    "x_rep = transform_single_pair(pairs_test[4])\n",
    "print(x_rep[2])\n",
    "print(sim_model.predict( [ [x_rep[0]] ] ))\n",
    "print(sim_model.predict( [ [x_rep[1]] ] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "x_batch_q = []\n",
    "x_batch_a = []\n",
    "for i, x in enumerate(pairs_test):\n",
    "    x_rep = transform_single_pair(x)\n",
    "    x_batch_q.append(x_rep[0])\n",
    "    x_batch_a.append(x_rep[1])\n",
    "    if (i > 0) & (i % 1000 == 0):\n",
    "        y_batch = sim_model.predict( [np.array(x_batch_q), np.array(x_batch_a)] )\n",
    "        #train_model.predict( [np.array(x_batch_q), np.array(x_batch_a)] )\n",
    "        y_pred.extend(y_batch)\n",
    "        x_batch_q = []\n",
    "        x_batch_a = []\n",
    "y_pred.extend( train_model.predict( [np.array(x_batch_q), np.array(x_batch_a)]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_answer = [ y[1] for y in y_pred ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd074346cc0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx_1 = np.argwhere(y_test == 1)\n",
    "idx_0 = np.argwhere(y_test == 0)\n",
    "sns.distplot(np.array(y_pred_answer)[idx_1], kde_kws={'label':'answer'}, color='blue')\n",
    "sns.distplot(np.array(y_pred_answer)[idx_0], kde_kws={'label':'non-answer'}, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_bin[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0 73083]\n",
      " [    0  4951]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd066eafa20>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD8CAYAAADUv3dIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAPc0lEQVR4nO3df6zd9V3H8dfr3LuKkTmmTS+1vWBjL2oBEzZkmqVAMpALLHQLxsBmhKXbNQs16tRYhilastVJmImh2F1GBUmEjSUjd3BtTSpNF6SzN2PpaJfqpY72VrjVgfyzIWv79o976M6u957vOfTcz/fTz30+yDc53x/3c94NzavvfL7fz/c6IgQASKNRdwEAsJgQugCQEKELAAkRugCQEKELAAkRugCQEKELAPOwvd32cdsvzHPetv/G9qTt/bbfUzUmoQsA83tY0nCb89dLGmpuI5L+tmpAQhcA5hEReyS92uaSdZL+PmbslXSe7eXtxuzvZYFzeeOEWPKG/+fdv7qh7hKQoR88f7/PdIyfvGxDx5nzxre2/q5mOtS3jEbEaBdft0LS0Zb9qeaxl+f7gQUPXQDIVTNguwnZM0boAiiLk86aHpM02LK/snlsXszpAihLo6/z7cyNSfqd5lMMvybp9YiYd2pBotMFUBqf8bRwy1B+TNLVkpbanpJ0t6R3SFJEbJM0LukGSZOSvi/pY1VjEroAytLD6YWIuLXifEi6o5sxCV0AZelhp7sQCF0AZUl7I61rhC6AstDpAkBCvXkqYcEQugDKwvQCACTE9AIAJESnCwAJEboAkFAfN9IAIB3mdAEgIaYXACAhOl0ASIhOFwASotMFgIRYBgwACTG9AAAJMb0AAAnR6QJAQoQuACTEjTQASIg5XQBIiOkFAEiIThcA0jGhCwDpELoAkJAbhC4AJEOnCwAJEboAkBChCwAp5Z25hC6AstDpAkBCjQYr0gAgGTpdAEgp78wldAGUJfdON+/JDwDoku2Otw7GGrZ9yPak7Y1znL/A9jO2n7e93/YNVWMSugCK4oY73tqOY/dJ2irpeklrJN1qe82sy/5M0pcj4jJJt0h6oKo+QhdAUXrY6V4haTIiDkfEm5Iel7Ru1jUh6aebn98l6T+rBmVOF0BRupnTtT0iaaTl0GhEjDY/r5B0tOXclKT3zRrizyX9k+3fk/RTkq6p+k5CF0BRugndZsCOVl44v1slPRwR99n+dUmP2r4kIk7N9wOELoCi9PDphWOSBlv2VzaPtVovaViSIuI52+dIWirp+HyDMqcLoCzuYmtvn6Qh26tsL9HMjbKxWdcckfQBSbL9y5LOkfRf7Qal0wVQlF4tA46IE7Y3SNopqU/S9og4YHuzpImIGJP0R5IetP2HmrmpdntERLtxCV0ARenl4oiIGJc0PuvYppbPByW9v5sxCV0AZcl7QRpzuqk8+/U9uunG6/TB4Wv10INncrMUpdh290f10q4tmnji03WXUpRerkhbCIRuAidPntRnP7NZD2z7or469rR2jD+lFycn6y4LNXv0a3u17o6tdZdRnNxDt3J6wfYvaWYVxormoWOSxiLiOwtZWEle+PZ+DQ5eqJWDM0+fDN9wo3Y/s0u/sHp1zZWhTs9+80VdsPxn6i6jOGf1C29s/6lmlr5Z0r82N0t6bK6XP2Bux6endf7y80/vLxsY0PT0dI0VAeXq1bsXFkpVp7te0sUR8cPWg7Y/L+mApL+c64dal9bd/8AXtP4TI3NdBgA9l3unWxW6pyT9nKSXZh1f3jw3p9aldW+cUNtn1haDZQMDeuXlV07vH5+e1sDAQI0VAeU620P3DyTtsv3v+tGLHy6QtFrShoUsrCQXX3Kpjhz5rqamjmpg2YB2jD+tLffeV3dZQJEyz9z2oRsRO2xfpJlXnLXeSNsXEScXurhS9Pf36867NumTIx/XqVMn9aEP36zVq4fqLgs1e2TL7Vr73iEtPe9cTe64R/dsG9cjTz5Xd1lnvbO901XzbTl7E9RStLVXXqW1V15VdxnIyG13Plx3CUVq1HSDrFOsSANQlMwbXUIXQFnodAEgITpdAEjorL+RBgBnk8wzl9AFUJZevcR8oRC6AIpCpwsACTGnCwAJZZ65hC6AstDpAkBCmWcuoQugLKxIA4CEmF4AgIQyz1xCF0BZ6HQBIKHMM5fQBVAWbqQBQEJMLwBAQoQuACSUeeYSugDKQqcLAAllnrmELoCy8PQCACTUyLzVzfv3WgBAl+zOt+qxPGz7kO1J2xvnuea3bB+0fcD2P1SNSacLoCi9upFmu0/SVknXSpqStM/2WEQcbLlmSNKdkt4fEa/ZXlY1Lp0ugKI03PlW4QpJkxFxOCLelPS4pHWzrvmEpK0R8ZokRcTxyvq6/yMBQL4aDXe82R6xPdGyjbQMtULS0Zb9qeaxVhdJusj2s7b32h6uqo/pBQBFsTqfXoiIUUmjZ/B1/ZKGJF0taaWkPbYvjYj/me8H6HQBFKWH0wvHJA227K9sHms1JWksIn4YEf8h6d80E8Lz19fdHwcA8ma7463CPklDtlfZXiLpFkljs655UjNdrmwv1cx0w+F2gzK9AKAovXpMNyJO2N4gaaekPknbI+KA7c2SJiJirHnuN2wflHRS0p9ExPfajUvoAihKLxdHRMS4pPFZxza1fA5Jn2puHSF0ARSFZcAAkFDmq4AJXQBlyf3dC4QugKLkHbmELoDC8BJzAEgo8/tohC6AsvD0AgAkxPQCACSUeaNL6AIoC50uACSUd+QSugAK05f5/AKhC6AoTC8AQEKZZy6hC6AsvHsBABLKPHMJXQBlYU4XABLqI3QBIJ3MnxgjdAGUhdAFgISY0wWAhOh0ASChzBtdQhdAWfozT11CF0BRMs9cQhdAWVgGDAAJZZ65hC6AsvD0AgAkxEvMASChzDOX0AVQFmf+W9IIXQBFodMFgIQIXQBIiBfeAEBCfY26K2gv8/IAoDsNu+Otiu1h24dsT9re2Oa6m22H7curxqTTBVCUXs3p2u6TtFXStZKmJO2zPRYRB2dd905Jvy/pGx3V15vyACAPdudbhSskTUbE4Yh4U9LjktbNcd09kj4n6Y1O6iN0ARSlIXe82R6xPdGyjbQMtULS0Zb9qeax02y/R9JgRDzdaX1MLwAoSjcPL0TEqKTRt/c9bkj6vKTbu/k5QhdAUfp796DuMUmDLfsrm8fe8k5Jl0ja3XxM7XxJY7ZvioiJeevrVXUAkIMePqa7T9KQ7VWaCdtbJH3krZMR8bqkpT/6Xu+W9MftAlcidAEUplcvMY+IE7Y3SNopqU/S9og4YHuzpImIGHs74xK6AIrSywVpETEuaXzWsU3zXHt1J2MSugCKkvsjWYQugKLwO9IAICFCFwASyjtyCV0Ahcm80SV0AZSF9+kCQEI8vQAACXEjDQASYnoBABJiegEAEqLTBYCE8o5cQhdAYfrodAEgncwzl9AFUBZnPsFA6AIoCp0uACTUoNMFgHTodAEgIZYBA0BCvfsN7AuD0AVQFJ5eAICEMp9dyP7dEMV49ut7dNON1+mDw9fqoQdH6y4HGdh290f10q4tmnji03WXUhR38V8dCN0ETp48qc9+ZrMe2PZFfXXsae0Yf0ovTk7WXRZq9ujX9mrdHVvrLqM4DXe+1VJfPV+7uLzw7f0aHLxQKwcH9Y4lSzR8w43a/cyuustCzZ795ot69fXv111GcRp2x1st9dXyrYvM8elpnb/8/NP7ywYGND09XWNFQLncxVaHtx26tj/W5tyI7QnbE8xfAkgp9073TJ5e+AtJfzfXiYgYlTQqSW+cUJzBdxRh2cCAXnn5ldP7x6enNTAwUGNFQLkyf3ihfeja3j/fKUmkRocuvuRSHTnyXU1NHdXAsgHtGH9aW+69r+6ygDJlnrpVne6ApOskvTbruCX9y4JUVKD+/n7dedcmfXLk4zp16qQ+9OGbtXr1UN1loWaPbLlda987pKXnnavJHffonm3jeuTJ5+ou66x3ti8DfkrSuRHxrdknbO9ekIoKtfbKq7T2yqvqLgMZue3Oh+suoUh5R25F6EbE+jbnPtL7cgDgDGWeuiwDBlAU3r0AAAllPqXL4ggAZenl4gjbw7YP2Z60vXGO85+yfdD2ftu7bF9YNSahC6AotjveKsbpk7RV0vWS1ki61faaWZc9L+nyiPgVSV+R9FdV9RG6AIpid75VuELSZEQcjog3JT0uaV3rBRHxTES89QKNvZJWVg1K6AIoSjfTC62vLGhuIy1DrZB0tGV/qnlsPusl/WNVfdxIA1CWLm6ktb6y4Iy+0v5tSZdLqnwYn9AFUJQePjJ2TNJgy/7K5rEf/z77Gkl3SboqIv63alCmFwAUpYdzuvskDdleZXuJpFskjf34d/kySV+QdFNEHO+kPjpdAEXp1XO6EXHC9gZJOyX1SdoeEQdsb5Y0ERFjku6VdK6kJ5pPQxyJiJvajUvoAihKL1ekRcS4pPFZxza1fL6m2zEJXQBFyX1FGqELoCiZZy6hC6AwmacuoQugKGf7S8wB4KySd+QSugBKk3nqEroAisJLzAEgocyndAldAGXJPHMJXQBlqXo5ed0IXQBFyTxzCV0AZck8cwldAIXJPHUJXQBF4ZExAEiIOV0ASKhB6AJASnmnLqELoChMLwBAQplnLqELoCx0ugCQEMuAASChvCOX0AVQmMwbXUIXQFlYkQYAKeWduYQugLJknrmELoCy8CvYASChzDNXjboLAIDFhE4XQFFy73QJXQBF4ZExAEiIThcAEiJ0ASAhphcAIKHcO10eGQNQFHexVY5lD9s+ZHvS9sY5zv+E7S81z3/D9s9XjUnoAihLj1LXdp+krZKul7RG0q2218y6bL2k1yJitaS/lvS5qvIIXQBFadgdbxWukDQZEYcj4k1Jj0taN+uadZIeaX7+iqQPuOIt6gs+p3tOf+az2gnZHomI0brryMEPnr+/7hKywd+L3uomc2yPSBppOTTa8v9ihaSjLeemJL1v1hCnr4mIE7Zfl/Szkv57vu+k001rpPoSLEL8vahJRIxGxOUt24L/40foAsDcjkkabNlf2Tw25zW2+yW9S9L32g1K6ALA3PZJGrK9yvYSSbdIGpt1zZik25qff1PSP0dEtBuU53TTYt4Oc+HvRYaac7QbJO2U1Cdpe0QcsL1Z0kREjEl6SNKjticlvaqZYG7LFaEMAOghphcAICFCFwASInQTqVpOiMXH9nbbx22/UHctSIfQTaDD5YRYfB6WNFx3EUiL0E2jk+WEWGQiYo9m7nhjESF005hrOeGKmmoBUCNCFwASInTT6GQ5IYBFgNBNo5PlhAAWAUI3gYg4Iemt5YTfkfTliDhQb1Wom+3HJD0n6RdtT9leX3dNWHgsAwaAhOh0ASAhQhcAEiJ0ASAhQhcAEiJ0ASAhQhcAEiJ0ASCh/wP5IjmJM010ZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_bin = [ 1 if y[0] > y [1] else 1  for y in y_pred ]\n",
    "y_pred_bin = np.array(y_pred_bin)\n",
    "\n",
    "y_test = np.array(y_test).flatten()\n",
    "y_pred_bin = y_pred_bin.flatten()\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_bin))\n",
    "cm = confusion_matrix(y_test, y_pred_bin)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm, cmap=\"Blues\", annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ranking)\n",
    "\n",
    "cache = {}\n",
    "bioasq_util.es = Elasticsearch(hosts=['168.176.36.10:9200'])\n",
    "index_name = '2018_pubmed_baseline_title_abs_mesh'\n",
    "doc_relative_url = 'http://www.ncbi.nlm.nih.gov/pubmed/'\n",
    "\n",
    "def return_cache(q,a):\n",
    "    global cache\n",
    "    key = q[0:40] + a[0:40]\n",
    "    if key not in cache:\n",
    "        pair = { 'body':q, 'text':a, 'label':0 }\n",
    "        data = transform_single_pair(pair)[0]\n",
    "        cache[key] = data\n",
    "    return cache[key]\n",
    "\n",
    "def rank_text(q, a):\n",
    "    try:\n",
    "        #pair = qa_data.QAPair('_', q, '_', a, '_')\n",
    "        pair = { 'body':q, 'text':a, 'label':0 }\n",
    "        #data = return_cache(q,a)\n",
    "        data = transform_single_pair(pair)[0]\n",
    "        score = sim_model.predict_proba(np.expand_dims(data,axis=0))[0][0]\n",
    "    except Exception as e:\n",
    "        print('rank_text>>',e)\n",
    "    return score\n",
    "\n",
    "def rank_bioasq_passage(doc_id, question, passage, section):\n",
    "    passage['beginSection'] = section\n",
    "    passage['endSection'] = section\n",
    "    passage['document'] = doc_relative_url + str(doc_id)\n",
    "    passage['score'] = 0\n",
    "    try:\n",
    "        if (len(question)>5) & (len(passage['text'])>15):\n",
    "            passage['score'] = rank_text(question, passage['text'])\n",
    "    except Exception as e:\n",
    "        print('rank_bioasq_passage>>',e)\n",
    "        print(question)\n",
    "        print(passage['text'])\n",
    "        sys.exit('Error')\n",
    "    return passage\n",
    "\n",
    "def rank_document(question, doc_id, doc_title, doc_abstract):\n",
    "    passages_ranked = []\n",
    "    chunks_title = ranking.split_chunks(doc_title)\n",
    "    title_passages_ranked = [ rank_bioasq_passage(doc_id, question, chunk, 'title') for chunk in chunks_title ]\n",
    "    chunks_abstract = ranking.split_chunks(doc_abstract)\n",
    "    abstract_passages_ranked = [ rank_bioasq_passage(doc_id, question, chunk, 'abstract') for chunk in chunks_abstract ]\n",
    "    return title_passages_ranked + abstract_passages_ranked\n",
    "\n",
    "def extract_rank_answer_candidates(question, docs):\n",
    "    snippets = []\n",
    "    w = np.linspace(0,0.0,len(docs))[::-1]\n",
    "    count_pass1 = 0\n",
    "    for i, doc in enumerate(docs):\n",
    "        doc_id = doc.replace(doc_relative_url,'')\n",
    "        doc_id, doc_title, doc_abstract = bioasq_util.get_doc(doc_id, index_name, remove_tags=True)\n",
    "        #doc_id = doc[0].replace(doc_relative_url,'')\n",
    "        #doc_title = doc[1]\n",
    "        #doc_abstract = doc[2]\n",
    "        snippets_ranked = rank_document(question, doc_id, doc_title, doc_abstract)\n",
    "        count_pass1 += len(snippets_ranked)\n",
    "        snippets_ranked = [ s for s in  snippets_ranked if s['score'] >= 0.6 ]\n",
    "        for s in snippets_ranked:\n",
    "            s['score'] = s['score'] + w[i]\n",
    "        snippets.extend(snippets_ranked)\n",
    "    #print('Percentage of remaining passages {}'.format(len(snippets)/count_pass1))\n",
    "    return snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [03:46<00:00,  2.26s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.0, 0.0, 0.0, 0.0, 1.0000000000000123e-05]\n",
      "Passage Scores [0.20142047868187313, 0.27511295809938635, 0.2029872004423393, 0.17992489965276406, 0.008677342626431389]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [02:38<00:00,  1.59s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.0, 0.0, 0.0, 0.0, 1.0000000000000123e-05]\n",
      "Passage Scores [0.40612412573842244, 0.2829193579872028, 0.263402177167222, 0.3352660330422217, 0.014260726017763275]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [02:32<00:00,  1.53s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.0, 0.0, 0.0, 0.0, 1.0000000000000123e-05]\n",
      "Passage Scores [0.29398680501292285, 0.3155806625975402, 0.2858036677331102, 0.2330343275723472, 0.009781087452062479]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [02:24<00:00,  1.45s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.0, 0.0, 0.0, 0.0, 1.0000000000000123e-05]\n",
      "Passage Scores [0.1850105885406818, 0.24923020890773134, 0.17943505910546254, 0.15946677985694938, 0.0023439530691751506]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [03:14<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Scores [0.0, 0.0, 0.0, 0.0, 1.0000000000000123e-05]\n",
      "Passage Scores [0.10357943113468213, 0.1361014393992736, 0.09632187464029379, 0.10066739520730479, 0.00039238302478022475]\n"
     ]
    }
   ],
   "source": [
    "#evaluate over aueb documents\n",
    "test_batch_docs = [ #('','8b5_ES_30_full.json')\n",
    "                ('6B1_golden.json', eval_home+'/goolgle_best_docs/aueb_nlp-bioasq6b-submissions/1-aueb-nlp-5.json'),\n",
    "                ('6B2_golden.json', eval_home+'/goolgle_best_docs/aueb_nlp-bioasq6b-submissions/2-aueb-nlp-5.json'),\n",
    "                ('6B3_golden.json', eval_home+'/goolgle_best_docs/aueb_nlp-bioasq6b-submissions/3-aueb-nlp-5.json'),\n",
    "                ('6B4_golden.json', eval_home+'/goolgle_best_docs/aueb_nlp-bioasq6b-submissions/4-aueb-nlp-5.json'),\n",
    "                ('6B5_golden.json', eval_home+'/goolgle_best_docs/aueb_nlp-bioasq6b-submissions/5-aueb-nlp-5.json')\n",
    "               ]\n",
    "    \n",
    "df = pd.DataFrame(columns=('batch', 'Mean precision', 'Recall', 'F-Measure', 'MAP', 'GMAP'))\n",
    "\n",
    "for i, batch_file in enumerate(test_batch_docs):\n",
    "    test_batch_json = json.load(open(batch_file[1]))\n",
    "    for sample in tqdm(test_batch_json['questions'], position=0):\n",
    "        snippets = extract_rank_answer_candidates(sample['body'], sample['documents'])\n",
    "        snippets_sorted = sorted(snippets, key = lambda i: (i['score']), reverse=True)\n",
    "        sample['snippets'] = snippets_sorted[0:10]\n",
    "        sample['documents'] = [ d[0] for d in sample['documents'] ][0:10]\n",
    "        sample['documents'] = sample['documents'][0:10]\n",
    "    submission = test_batch_json.copy()\n",
    "    for q in submission['questions']:\n",
    "        for s in q['snippets']:\n",
    "            del s['score']\n",
    "    submission_file_name =  working_folder + \"/\" + model_id + '_'+batch_file[1].split('/')[-1]\n",
    "    json.dump(submission, open(submission_file_name, 'w'))\n",
    "    docs_score, pass_score = bioasq_eval.get_scores_phaseA(batch_file[0], submission, path_home=eval_home)\n",
    "    print('Document Scores',docs_score)\n",
    "    print('Passage Scores',pass_score)\n",
    "    df.loc[i] = [ batch_file[0].split('.')[0] + '_' + batch_file[1].split('/')[-1].split('.')[0] ] + pass_score\n",
    "\n",
    "df.to_csv(working_folder + \"/\" + model_id+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_tx = p_tqdm.p_map(transform_single_pair, pairs)\n",
    "\n",
    "for i, pair in enumerate(pairs): \n",
    "    pair['representation'] = pairs_tx[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = transform_single_pair(pairs[0])\n",
    "ts2 = transform_single_pair(pairs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts3 = [ts] + [ts2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v['test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
